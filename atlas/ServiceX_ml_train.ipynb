{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb414da8",
   "metadata": {},
   "source": [
    "## Notebook for ML training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad6c4950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils \n",
    "import ml_framework.data_fetcher  \n",
    "import json\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c17a76",
   "metadata": {},
   "source": [
    "###  1) Extract dataset metadata info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e73995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"ntuple_production/file_metadata.json.gz\"\n",
    "with gzip.open(fname) as f:\n",
    "    dataset_info = json.loads(f.read().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baca89b5",
   "metadata": {},
   "source": [
    "#### Get rucio containers for signal and background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "555ed6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H+ -> cb signal in 40 DSIDs for 9e+06 total events\n",
      "wjets in 54 DSIDs for 7e+09 total events\n",
      "ttbar_nom in 9 DSIDs for 2e+09 total events\n"
     ]
    }
   ],
   "source": [
    "total_sig = 0\n",
    "total_wjets = 0\n",
    "total_ttbar = 0\n",
    "signal_containers = {}\n",
    "wjets_containers = {}\n",
    "ttbar_containers = {}\n",
    "\n",
    "for container, metadata in dataset_info.get(\"Hplus_cb\", {}).items():\n",
    "    evts = metadata.get(\"nevts_input\", 0)\n",
    "    total_sig += evts\n",
    "    mass = utils.hplus_signal_mass(container)\n",
    "    ntuples = metadata.get(\"output\", 0)\n",
    "    _, _, campaign = utils.dsid_rtag_campaign(container)\n",
    "    signal_containers[f\"{mass}_{campaign}\"] = {'DSID': container, 'Events': evts, 'Ntuples': ntuples}\n",
    "\n",
    "for container, metadata in dataset_info.get(\"wjets\", {}).items():\n",
    "    evts = metadata.get(\"nevts_input\", 0)\n",
    "    total_wjets += evts\n",
    "    ntuples = metadata.get(\"output\", 0)\n",
    "    did, _, campaign = utils.dsid_rtag_campaign(container)\n",
    "    wjets_containers[f\"{did}_{campaign}\"] = {'DSID': container, 'Events': evts, 'Ntuples': ntuples}\n",
    "\n",
    "for container, metadata in dataset_info.get(\"ttbar_nom\", {}).items():\n",
    "    evts = metadata.get(\"nevts_input\", 0)\n",
    "    total_ttbar += evts\n",
    "    ntuples = metadata.get(\"output\", 0)\n",
    "    did, _, campaign = utils.dsid_rtag_campaign(container)\n",
    "    ttbar_containers[f\"{did}_{campaign}\"] = {'DSID': container, 'Events': evts, 'Ntuples': ntuples}\n",
    "\n",
    "print(f\"H+ -> cb signal in {len(signal_containers)} DSIDs for {total_sig:.0e} total events\")\n",
    "print(f\"wjets in {len(wjets_containers)} DSIDs for {total_wjets:.0e} total events\")\n",
    "print(f\"ttbar_nom in {len(ttbar_containers)} DSIDs for {total_ttbar:.0e} total events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffbcfa4-e584-4a4c-a8fc-09c913b2b3e4",
   "metadata": {},
   "source": [
    "#### Get NTuples for TTbar nominal events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd8c2138-7acd-4441-95fb-cdf3dd7c6d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntuples=[]\n",
    "for value in ttbar_containers.values():\n",
    "    ntuples.append(\"user.alheld:\"+value[\"Ntuples\"][:-1])  # curent fix for output in metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37d3467b-ea27-4726-8aa1-00170670dfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rucio DSIDs ntuples for ttbar nominal: \n",
      " user.alheld:user.alheld.410470.PhPy8EG.DAOD_PHYSLITE.e6337_s3681_r13144_r13146_p6697.IC-v1_output\n",
      " user.alheld:user.alheld.410470.PhPy8EG.DAOD_PHYSLITE.e6337_s3681_r13145_r13146_p6697.IC-v1_output\n",
      " user.alheld:user.alheld.410470.PhPy8EG.DAOD_PHYSLITE.e6337_s3681_r13167_r13146_p6697.IC-v1_output\n",
      " user.alheld:user.alheld.601229.PhPy8EG.DAOD_PHYSLITE.e8514_s4159_r15530_p6697.IC-v1_output\n",
      " user.alheld:user.alheld.601229.PhPy8EG.DAOD_PHYSLITE.e8514_s4162_r15540_p6697.IC-v1_output\n",
      " user.alheld:user.alheld.601229.PhPy8EG.DAOD_PHYSLITE.e8514_s4369_r16083_p6697.IC-v1_output\n",
      " user.alheld:user.alheld.601230.PhPy8EG.DAOD_PHYSLITE.e8514_s4159_r15530_p6697.IC-v1_output\n",
      " user.alheld:user.alheld.601230.PhPy8EG.DAOD_PHYSLITE.e8514_s4162_r15540_p6697.IC-v1_output\n",
      " user.alheld:user.alheld.601230.PhPy8EG.DAOD_PHYSLITE.e8514_s4369_r16083_p6697.IC-v1_output\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Rucio DSIDs ntuples for ttbar nominal: \\n\",\n",
    "    \"\\n \".join(ntuples),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44092445-4b17-4503-99b2-083167e776a9",
   "metadata": {},
   "source": [
    "### 2) Use ServiceX to check the file structure w/o pulling data\n",
    "To prepare your ServiceX query, you can check what branches are available in the targeted samples. \n",
    "Interface to be improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b21c48bb-96d7-478a-b5c9-5ff3fc7efc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f926b939bf524b7491d849c90d0f9391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'awkward.types.recordtype.RecordType'> contains 3 fields: ['EventLoop_FileExecuted', 'EventLoop_JobStats', 'reco']\n"
     ]
    }
   ],
   "source": [
    "from servicex_analysis_utils import get_structure\n",
    "\n",
    "#Single sample example\n",
    "array_structure=get_structure(ntuples[0], array_out=True)\n",
    "\n",
    "record=array_structure[ntuples[0]].content\n",
    "print(f\"{type(record)} contains 3 fields: {record.fields}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e31e2fd-3b44-4e9a-bf11-a3d2ee21936c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 3876 branches in user.alheld:user.alheld.410470.PhPy8EG.DAOD_PHYSLITE.e6337_s3681_r13144_r13146_p6697.IC-v1_output\n",
      "\n",
      "125 available jet_pt variables: \n",
      " jet_pt_NOSYS\n",
      " jet_pt_JET_BJES_Response__1up\n",
      " jet_pt_JET_BJES_Response__1down\n",
      " jet_pt_JET_EffectiveNP_Detector1__1up\n",
      " jet_pt_JET_EffectiveNP_Detector1__1down\n"
     ]
    }
   ],
   "source": [
    "#get branches from reco ttree\n",
    "reco_branches = record.contents[2].fields\n",
    "\n",
    "print(f\"Total of {len(reco_branches)} branches in {ntuples[0]}\\n\")\n",
    "\n",
    "pt_variations = [b for b in reco_branches if \"jet_pt\" in b] \n",
    "print(\n",
    "    f\"{len(pt_variations)} available jet_pt variables: \\n\",\n",
    "    \"\\n \".join(pt_variations[0:5]),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b3b185e-28a8-4092-9ac0-8e35b69bf76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146 available btag selections @ 77 WP: \n",
      " jet_GN2v01_FixedCutBEff_77_select\n",
      " jet_select_GN2v01_FixedCutBEff_77_NOSYS\n",
      " jet_select_GN2v01_FixedCutBEff_77_EG_RESOLUTION_AF3__1down\n",
      " jet_select_GN2v01_FixedCutBEff_77_EG_RESOLUTION_AF3__1up\n",
      " jet_select_GN2v01_FixedCutBEff_77_EG_RESOLUTION_ALL__1down\n"
     ]
    }
   ],
   "source": [
    "btag = [b for b in reco_branches if \"GN2v01_FixedCutBEff_77\" in b]\n",
    "print(\n",
    "    f\"{len(btag)} available btag selections @ 77 WP: \\n\",\n",
    "    \"\\n \".join(btag[0:5]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74e81fa-f1a6-459b-b16e-365947be75ab",
   "metadata": {},
   "source": [
    "### 3) Build query and fetch samples with the `data_fetcher` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16fdfab3-9e99-40dd-969d-e4e046ec59c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_framework.data_fetcher as fetcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0df2e5c-7f3b-4b49-8c1c-cadd2cb12220",
   "metadata": {},
   "source": [
    "#### 3.a) Define event-level cuts on available branches:\n",
    "\n",
    "- At least 4 jets with pT > 25 GeV and one jet in the barrel\n",
    "\n",
    "- At least 2 electrons with no pT cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "843cbf5c-d7eb-4c64-adde-562345e4a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jet_pt(evt):\n",
    "    return evt[\"jet_pt_NOSYS\"].Where(lambda pt: pt > 25_000).Count() > 3\n",
    "\n",
    "def jet_eta(evt):\n",
    "    return evt[\"jet_eta\"].Where(lambda eta: abs(eta) < 2.2).Count() > 0\n",
    "\n",
    "def el_count(evt):\n",
    "    return evt[\"el_pt_NOSYS\"].Count()>1\n",
    "\n",
    "cuts = [jet_pt, jet_eta, el_count]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06f770a-adb8-439e-8b06-fb2756044f4c",
   "metadata": {},
   "source": [
    "#### 3.b) Define the branch selection to be dumped by ServiceX workers in the result files\n",
    "\n",
    "- Branch labels in the final files\n",
    "- Branches to be saved w or w/o final transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "749d0eef-9589-4ab9-8394-fc00074b8d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def branch_select(evt):\n",
    "    return {\n",
    "        \"jet_pt\": evt[\"jet_pt_NOSYS\"].Select(lambda pt: pt / 1000.0),\n",
    "        \"btag\": evt[\"jet_GN2v01_FixedCutBEff_77_select\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27328d1-c9df-4827-81c5-c1d32a05f0ab",
   "metadata": {},
   "source": [
    "#### 3.c) Configure the transformation request \n",
    "- tree_name to open\n",
    "- samples to get (list of samples allowed)\n",
    "- number of files per sample\n",
    "- output folder for .parquet result files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32aa4be4-a078-4ef4-a742-90cd8e43858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = fetcher.RunConfig(\n",
    "    tree_name=\"reco\",\n",
    "    dataset=ntuples[0],\n",
    "    output_folder=\"./ml_framework/data/\",\n",
    "    files_per_sample=2,\n",
    "    request_name=\"TTbar_nom\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51470d7e-1e53-4158-a218-11a36f5a67c5",
   "metadata": {},
   "source": [
    "#### 3.d) Construct the ServiceX query object\n",
    "Using `ServiceXQuery` the full FuncADL query is constructed and the ServiceX request specifications is taken care for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "140beb50-fef0-4101-8bd9-c4d4b5962104",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = fetcher.ServiceXQuery(cuts, branch_select, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8339946d-06d7-4436-a769-868a7716e32d",
   "metadata": {},
   "source": [
    "#### 3.d) Send the query to the ServiceX transformers\n",
    "\n",
    "Run `deliver` and parse kwargs to the servicex call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c52d9db0-a50a-4aba-ac58-92fe93d0f624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e8502d191649aea88fb5380fd5e131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ReturnValueException",
     "evalue": "Exception occurred while making ServiceX request.\nTraceback (most recent call last):\n  File \"/Users/acordeir/Documents/IRIS-HEP/IntegChallenge/integration-challenge/atlas/.pixi/envs/default/lib/python3.13/site-packages/servicex/query_core.py\", line 730, in as_files_async\n    return await self.submit_and_download(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        signed_urls_only=False, expandable_progress=progress\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/acordeir/Documents/IRIS-HEP/IntegChallenge/integration-challenge/atlas/.pixi/envs/default/lib/python3.13/site-packages/servicex/query_core.py\", line 400, in submit_and_download\n    _ = await monitor_task  # raise exception, if it is there\n        ^^^^^^^^^^^^^^^^^^\n  File \"/Users/acordeir/Documents/IRIS-HEP/IntegChallenge/integration-challenge/atlas/.pixi/envs/default/lib/python3.13/site-packages/servicex/query_core.py\", line 515, in transform_status_listener\n    raise ServiceXException(err_str)\nservicex.query_core.ServiceXException: Request \"TTbar_nom\" was canceled\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mReturnValueException\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mquery\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeliver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_local_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IRIS-HEP/IntegChallenge/integration-challenge/atlas/ml_framework/data_fetcher.py:104\u001b[39m, in \u001b[36mServiceXQuery.deliver\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    102\u001b[39m files = deliver(spec, **kwargs)\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.join_result_parquet:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrite_to_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m     \u001b[38;5;66;03m# Logging\u001b[39;00m\n\u001b[32m    106\u001b[39m     logging.warning(\u001b[33m\"\u001b[39m\u001b[33mFetched data written to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.config.output_folder)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IRIS-HEP/IntegChallenge/integration-challenge/atlas/ml_framework/data_fetcher.py:71\u001b[39m, in \u001b[36mServiceXQuery.write_to_parquet\u001b[39m\u001b[34m(self, files, **kwargs)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrite_to_parquet\u001b[39m(\u001b[38;5;28mself\u001b[39m, files: \u001b[38;5;28mdict\u001b[39m, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     arrays = \u001b[43mto_awk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key, arr \u001b[38;5;129;01min\u001b[39;00m arrays.items():\n\u001b[32m     74\u001b[39m         logging.info(\u001b[33m\"\u001b[39m\u001b[33mKey: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m, Entries: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m, key, \u001b[38;5;28mlen\u001b[39m(arr))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IRIS-HEP/IntegChallenge/integration-challenge/atlas/.pixi/envs/default/lib/python3.13/site-packages/servicex_analysis_utils/materialization.py:56\u001b[39m, in \u001b[36mto_awk\u001b[39m\u001b[34m(deliver_dict, dask, iterator, **kwargs)\u001b[39m\n\u001b[32m     53\u001b[39m awk_arrays = {}\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sample, paths \u001b[38;5;129;01min\u001b[39;00m deliver_dict.items():\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m paths:\n\u001b[32m     57\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     58\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDelivered result file path list for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is empty.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     59\u001b[39m         )\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# Check file type\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IRIS-HEP/IntegChallenge/integration-challenge/atlas/.pixi/envs/default/lib/python3.13/site-packages/servicex/servicex_client.py:110\u001b[39m, in \u001b[36mGuardList.__len__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.valid():\n\u001b[32m    109\u001b[39m     data = cast(\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;28mself\u001b[39m._data)\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m data\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    112\u001b[39m     data = cast(Sequence, \u001b[38;5;28mself\u001b[39m._data)\n",
      "\u001b[31mReturnValueException\u001b[39m: Exception occurred while making ServiceX request.\nTraceback (most recent call last):\n  File \"/Users/acordeir/Documents/IRIS-HEP/IntegChallenge/integration-challenge/atlas/.pixi/envs/default/lib/python3.13/site-packages/servicex/query_core.py\", line 730, in as_files_async\n    return await self.submit_and_download(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        signed_urls_only=False, expandable_progress=progress\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/acordeir/Documents/IRIS-HEP/IntegChallenge/integration-challenge/atlas/.pixi/envs/default/lib/python3.13/site-packages/servicex/query_core.py\", line 400, in submit_and_download\n    _ = await monitor_task  # raise exception, if it is there\n        ^^^^^^^^^^^^^^^^^^\n  File \"/Users/acordeir/Documents/IRIS-HEP/IntegChallenge/integration-challenge/atlas/.pixi/envs/default/lib/python3.13/site-packages/servicex/query_core.py\", line 515, in transform_status_listener\n    raise ServiceXException(err_str)\nservicex.query_core.ServiceXException: Request \"TTbar_nom\" was canceled\n"
     ]
    }
   ],
   "source": [
    "query.deliver(ignore_local_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db211d5a-bb69-4971-9c5d-7f9a30e1c99e",
   "metadata": {},
   "source": [
    "### 4) \"Seperate notebook\" to load the result files etc etc ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b9dba3-3e48-42ac-8651-b25a80c445b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./ml_framework/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7c3543-4700-4053-8335-0c086492e64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110599d8-f6fe-41c7-b8d0-b33e32de0a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ak.from_parquet(\"./ml_framework/data/user.alheld:user.alheld.410470.PhPy8EG.DAOD_PHYSLITE.e6337_s3681_r13144_r13146_p6697.IC-v1_output.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1377ecd-33cc-4206-9a2f-79cb352f6716",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42f92b1-6336-4b0f-bc3a-c77549a5ef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"btag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87869600-ae66-4b45-9546-598f63724d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.output_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c9038f-a362-4ef9-9066-ff42990daad3",
   "metadata": {},
   "source": [
    "# to do \n",
    "- Fix name request length / file name\n",
    "- add btag cut\n",
    "- fix utils issues \n",
    "- test multi sample\n",
    "- test 20tb ntuples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a86c6c7-05dd-42e8-a01a-ab75339b475d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
