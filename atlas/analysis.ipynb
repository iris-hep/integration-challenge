{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "021c38db-e1c9-4137-b7f4-87a094ca5108",
   "metadata": {},
   "source": [
    "# ATLAS Integration Challenge\n",
    "\n",
    "The next cell updates dependencies, make sure to restart the kernel afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f15ac-903b-4f33-b775-e7c14a3647a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade --quiet atlas_schema\n",
    "! pip install --upgrade --quiet --pre mplhep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b8b953-dc21-4d5c-899d-b1f0b03c70b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import gzip\n",
    "import json\n",
    "import math\n",
    "import pathlib\n",
    "import time\n",
    "\n",
    "import awkward as ak\n",
    "import cloudpickle\n",
    "import dask\n",
    "import dask.bag\n",
    "import hist\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep\n",
    "import numpy as np\n",
    "import uproot\n",
    "import vector\n",
    "\n",
    "from atlas_schema.schema import NtupleSchema\n",
    "from coffea import processor\n",
    "from coffea.nanoevents import NanoEventsFactory\n",
    "from dask.distributed import Client, PipInstall, performance_report\n",
    "from IPython.display import display\n",
    "\n",
    "import utils\n",
    "\n",
    "vector.register_awkward()\n",
    "mplhep.style.use(mplhep.style.ATLAS1)\n",
    "\n",
    "client = Client(\"tls://localhost:8786\")\n",
    "\n",
    "plugin = PipInstall(packages=[\"atlas_schema\"], pip_options=[\"--upgrade\"])\n",
    "client.register_plugin(plugin)\n",
    "\n",
    "cloudpickle.register_pickle_by_value(utils)\n",
    "\n",
    "# utils.new_output_path()  # optional: create new path to store output in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bbd464-1423-4353-81cc-f43806f04a7e",
   "metadata": {},
   "source": [
    "### Fileset preparation\n",
    "\n",
    "Comment out the desired version in the next cell to run over the full input dataset or a subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536e4026-6004-46ef-9f96-6983ed726957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full scale\n",
    "# fileset, input_size_GB = utils.get_fileset(campaign_filter=None, dsid_filter=None, max_files_per_sample=None)\n",
    "\n",
    "# 9% of full scale, using 2022 data + MC\n",
    "# fileset, input_size_GB = utils.get_fileset(campaign_filter=[\"mc23a\", \"data22\"], dsid_filter=None, max_files_per_sample=None)\n",
    "\n",
    "fileset, input_size_GB = utils.get_fileset(campaign_filter=[\"mc23a\", \"mc23d\", \"data22\", \"data23\"], dsid_filter=None, max_files_per_sample=None)\n",
    "\n",
    "# minimal setup for debugging\n",
    "# fileset, input_size_GB = utils.get_fileset(campaign_filter=[\"mc23a\"], dsid_filter=[\"601229\"], max_files_per_sample=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac19e7b-d5c7-4dbf-acc2-298bb4e849cc",
   "metadata": {},
   "source": [
    "### 200 Gbps-style `uproot.iterate` version\n",
    "\n",
    "Alternative setup in the style of https://github.com/iris-hep/idap-200gbps-atlas/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e59a92-619e-45a2-ad0b-7423c1f85723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tqdm.notebook\n",
    "\n",
    "# all_files = []\n",
    "# for k, v in fileset.items():\n",
    "#     all_files += v[\"files\"] if \"period\" not in k else []  # skip data (which has less branches)\n",
    "\n",
    "# columns_to_read = json.load(pathlib.Path(\"columns_to_preload.json\").open())[\"all_systematics\"]\n",
    "\n",
    "# def read_branches(fname, branches):\n",
    "#     try:\n",
    "#         t0 = time.time()\n",
    "#         with uproot.open(fname) as f:\n",
    "#             for _ in f[\"reco\"].iterate(expressions=branches, step_size=25_000):\n",
    "#                 pass\n",
    "#             size_read = f.file.source.num_requested_bytes / 1_000**2\n",
    "#         t1 = time.time()\n",
    "#         return {\"t0\": t0, \"t1\": t1, \"MBread\": size_read}\n",
    "#     except:\n",
    "#         return {\"t0\": 0, \"t1\": 0, \"MBread\": 0, \"fname\": fname}\n",
    "\n",
    "# t0 = time.time()\n",
    "# tasks = [dask.delayed(read_branches)(fname, columns_to_read) for fname in all_files]\n",
    "# futures = client.compute(tasks)\n",
    "\n",
    "# with tqdm.notebook.tqdm(total=len(futures)) as pbar:\n",
    "#   for future in dask.distributed.as_completed(futures):\n",
    "#     pbar.update(1)\n",
    "\n",
    "# res = [f.result() for f in futures]\n",
    "# t1 = time.time()\n",
    "\n",
    "# GBread_total = sum([r[\"MBread\"] for r in res])/1_000\n",
    "# print(f\"{GBread_total:.2f} GB read total in {t1-t0:.1f} sec, {GBread_total * 8 / (t1-t0):.2f} Gbps, fraction read: {GBread_total/input_size_GB:.2%}\")\n",
    "\n",
    "# # debug failures\n",
    "# failed_files = [r.get(\"fname\") for r in res if r.get(\"fname\") is not None]\n",
    "# print(f\"{len(failed_files)} failures: {failed_files}\")\n",
    "\n",
    "# for failed in failed_files:\n",
    "#     read_branches(failed, columns_to_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a081b9-c4ec-41c8-830c-a727e56ff472",
   "metadata": {},
   "source": [
    "### Simple non-distributed reading\n",
    "\n",
    "This cell is for debugging and to ensure the basic non-distributed infrastructure works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6c685f-7e9c-4c5b-8f80-19f1543de32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCPTSchema(NtupleSchema):\n",
    "    # mcChannelNumber not defined for data\n",
    "    event_ids = {\"actualInteractionsPerCrossing\", \"averageInteractionsPerCrossing\", \"eventNumber\", \"mcChannelNumber\", \"runNumber\"}\n",
    "    mixins = {\n",
    "        \"globalTriggerEffSF\": \"Weight\",  # events[\"NOSYS\"].globalTriggerEffSF.emu\n",
    "        \"globalTriggerMatch\": \"Systematic\",  # events[\"NOSYS\"].globalTriggerMatch.emu\n",
    "        **NtupleSchema.mixins\n",
    "    }\n",
    "\n",
    "events = NanoEventsFactory.from_root(\n",
    "    {list(fileset[list(fileset.keys())[0]][\"files\"])[0]: \"reco\"},\n",
    "    mode=\"virtual\",\n",
    "    schemaclass=TCPTSchema,\n",
    "    entry_stop=1000,\n",
    "    access_log=(access_log := []),\n",
    ").events()\n",
    "\n",
    "h = hist.new.Regular(30, 0, 300, label=\"leading electron $p_T$\").StrCat([], name=\"variation\", growth=True).Weight()\n",
    "\n",
    "for variation in events.systematic_names:\n",
    "    if variation != \"NOSYS\" and \"EG_SCALE_ALL\" not in variation:\n",
    "        continue\n",
    "\n",
    "    cut = events[variation][\"pass\"][\"ejets\"] == 1\n",
    "    h.fill(events[variation][cut==1].el.pt[:, 0] / 1_000, variation=variation)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for variation in h.axes[1]:\n",
    "    h[:, variation].plot(histtype=\"step\", label=variation, ax=ax)\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31f4dd8-07aa-4dd0-b50f-013349abe59a",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "\n",
    "This step touches every file to extract metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abaeac0-ca4c-4a36-8426-10438c4e034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = processor.Runner(\n",
    "    executor = processor.DaskExecutor(client=client, treereduction=4),\n",
    "    # executor = processor.IterativeExecutor(),  # to run locally\n",
    "    schema=TCPTSchema,\n",
    "    savemetrics=True,\n",
    "    chunksize=25_000,\n",
    "    skipbadfiles=True,\n",
    "    align_clusters=False,\n",
    "    # maxchunks=1  # for debugging only\n",
    ")\n",
    "\n",
    "\n",
    "def extract_sumw(f):\n",
    "    \"\"\"read initial sum of weights, custom function to be injected during pre-processing\"\"\"\n",
    "    matching_histograms = f.keys(filter_name=\"CutBookkeeper*NOSYS\")\n",
    "    if len(matching_histograms):\n",
    "        sumw = float(f[matching_histograms[0]].values()[1])\n",
    "    else:\n",
    "        sumw = 0  # for data\n",
    "    return {\"sumw\": sumw}\n",
    "\n",
    "\n",
    "with performance_report(filename=f\"{utils.get_output_path()}/preprocess.html\"):\n",
    "    # custom pre-processing: like coffea, but with more metadata\n",
    "    t0 = time.time()\n",
    "    preprocess_output = utils.custom_preprocess(fileset, client=client, chunksize=run.chunksize, custom_func=extract_sumw)\n",
    "    t1 = time.time()\n",
    "\n",
    "\n",
    "# calculate dataset-aggregated sumw (without chunk duplication) and update preprocessing metadata accordingly\n",
    "sumw_dict = collections.defaultdict(dict)\n",
    "for chunk in preprocess_output:\n",
    "    sumw_dict[chunk.dataset][chunk.filename] = chunk.usermeta[\"sumw\"]\n",
    "\n",
    "for chunk in preprocess_output:\n",
    "    # for data all sumw entries are 0, set the total to 1 manually\n",
    "    chunk.usermeta.update({\"sumw_dataset\": sum(sumw_dict[chunk.dataset].values()) or 1})\n",
    "\n",
    "\n",
    "# visualize task stream\n",
    "ts = client.get_task_stream(start=f\"{math.ceil(time.time()-t0)}s\")\n",
    "_ = utils.plot_taskstream(ts)\n",
    "\n",
    "print(f\"generated list of {len(preprocess_output)} work items in {t1-t0:.1f} sec:\\n{preprocess_output[:3]}\")\n",
    "\n",
    "# write to disk\n",
    "with open(f\"{utils.get_output_path()}/preprocess_output.json\", \"w\") as f:\n",
    "    json.dump(utils.preprocess_to_json(preprocess_output), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4667b1bf-0ff3-4ccf-93e9-4f4a8e0aa3c7",
   "metadata": {},
   "source": [
    "### Processing\n",
    "\n",
    "This either uses `coffea`'s `Runner` interface or a custom `dask.bag` method for more metadata tracking.\n",
    "Configure this via `USE_CUSTOM_PROCESSING`.\n",
    "The custom approach is needed for instantaneous data rate calculation in this notebook.\n",
    "\n",
    "Track XCache egress: [link](https://grafana.mwt2.org/d/EKefjM-Sz/af-network-200gbps-challenge?orgId=1&from=now-1h&to=now&viewPanel=panel-205&refresh=5s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a325d073-d017-4443-a539-b64d9b8feeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait for specific worker count\n",
    "# import datetime\n",
    "# nworker_target = 1\n",
    "# while (nworkers := len(client.scheduler_info()['workers'])) < nworker_target:\n",
    "#     print(datetime.datetime.now(), nworkers, end=\"\\r\")\n",
    "#     time.sleep(1)\n",
    "# print(datetime.datetime.now(), nworkers)\n",
    "\n",
    "# configure whether to use coffea Runner interface or custom dask.bag-based version\n",
    "USE_CUSTOM_PROCESSING = True\n",
    "\n",
    "\n",
    "class Analysis(processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        self.h = hist.new.Regular(20, 0, 1_000, label=\"$m_{jj}$ [GeV]\").\\\n",
    "            StrCat([], name=\"category\", growth=True).\\\n",
    "            StrCat([], name=\"variation\", growth=True).\\\n",
    "            Weight()\n",
    "\n",
    "    def get_weight(self, events, variation, cut, sumw):\n",
    "        if events.metadata[\"dsid\"] == \"data\":\n",
    "            return 1.0\n",
    "\n",
    "        # TODO: beamspot weight for mc20\n",
    "        weight = events[variation][cut==1].weight.mc * events.metadata[\"weight_xs\"] * events.metadata[\"lumi\"] / sumw *\\\n",
    "                 events[variation][cut==1].weight.pileup * events[variation][cut==1].weight.jvt_effSF *\\\n",
    "                 events[variation][cut==1].weight.ftag_effSF_GN2v01_Continuous *\\\n",
    "                 events[variation][cut==1].weight.leptonSF_tight * events[variation][cut==1].globalTriggerEffSF.emu\n",
    "        return weight\n",
    "\n",
    "    def process(self, events):\n",
    "        sumw = events.metadata[\"sumw_dataset\"]  # TODO: systematics-dependent normalization\n",
    "        for variation in events.systematic_names:\n",
    "            if \"EFF_\" in variation:\n",
    "                continue  # weight variations are handled in dedicated loop during nominal\n",
    "\n",
    "            # only run over subset of systematics\n",
    "            # if variation not in [\"NOSYS\"] + [name for name in events.systematic_names if \"JET_JER_Effective\" in name]:\n",
    "            #     continue\n",
    "\n",
    "            cut = events[variation][\"pass\"][\"ejets\"] == 1\n",
    "            weight = self.get_weight(events, variation, cut, sumw)\n",
    "            mjj = (events[variation][cut==1].jet[:, 0] + events[variation][cut==1].jet[:, 1]).mass\n",
    "            self.h.fill(mjj / 1_000, category=events.metadata[\"category\"], variation=variation, weight=weight)\n",
    "\n",
    "            if variation == \"NOSYS\":\n",
    "                # fill all weight variations during nominal\n",
    "                for weight_sys_name in [var for var in events.systematic_names if \"EFF_\" in var]:\n",
    "                    weight_var = self.get_weight(events, weight_sys_name, cut, sumw)\n",
    "                    self.h.fill(mjj / 1_000, category=events.metadata[\"category\"], variation=weight_sys_name, weight=weight_var)\n",
    "\n",
    "        return {\"hist\": self.h, \"meta\": {}}\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        pass\n",
    "\n",
    "\n",
    "# load pre-processing information from disk\n",
    "with open(f\"{utils.get_output_path()}/preprocess_output.json\") as f:\n",
    "    preprocess_output = utils.json_to_preprocess(json.load(f))\n",
    "\n",
    "client.run_on_scheduler(utils.start_tracking)  # track worker count on scheduler\n",
    "t0 = time.time()  # track walltime\n",
    "\n",
    "if USE_CUSTOM_PROCESSING:\n",
    "    # configure here whether to preload branches\n",
    "    columns_to_preload = json.load(pathlib.Path(\"columns_to_preload.json\").open())[\"all_systematics\"]  # or [], [\"JET_JER_Effective\"]\n",
    "\n",
    "    with performance_report(filename=f\"{utils.get_output_path()}/process_custom.html\"):\n",
    "        out, report = utils.custom_process(preprocess_output, processor_class=Analysis, schema=run.schema, client=client, preload=columns_to_preload)\n",
    "\n",
    "    print(f\"preloaded columns: {len(columns_to_preload)}, {columns_to_preload[:4]} {\"etc.\" if len(columns_to_preload) > 4 else \"\"}\")\n",
    "    print(f\"preloaded but unused columns: {len([c for c in columns_to_preload if c not in report[\"columns\"]])}\")\n",
    "    print(f\"used but not preloaded columns: {len([c for c in report[\"columns\"] if c not in columns_to_preload])}\")\n",
    "\n",
    "    # shortened version of report, dropping extra columns and per-chunk information\n",
    "    display(\n",
    "        dict((k, v) for k, v in report.items() if k not in [\"columns\", \"chunk_info\"]) | \n",
    "        {\"columns\": report[\"columns\"][0:10] + [\"...\"]} | \n",
    "        {\"chunk_info\": list(report[\"chunk_info\"].items())[:2] + [\"...\"]}\n",
    "    )\n",
    "\n",
    "else:\n",
    "    # coffea Runner-based processing\n",
    "    with performance_report(filename=f\"{utils.get_output_path()}/process.html\"):\n",
    "        out, report = run(preprocess_output, processor_instance=Analysis())\n",
    "\n",
    "    # shortened version of report, dropping extra columns\n",
    "    display(dict((k, v) for k, v in report.items() if k != \"columns\") | ({\"columns\": report[\"columns\"][0:10] + [\"...\"]}))\n",
    "\n",
    "t1 = time.time()\n",
    "worker_count_dict = client.run_on_scheduler(utils.stop_tracking)  # stop tracking, read out data, get average\n",
    "nworker_avg = utils.get_avg_num_workers(worker_count_dict)\n",
    "\n",
    "# histogram info\n",
    "num_hists = 0\n",
    "for cat in out[\"hist\"].axes[1]:\n",
    "    for sys in out[\"hist\"][:, cat, :].axes[1]:\n",
    "        if sum(out[\"hist\"][:, cat, sys].values()) > 0.0:\n",
    "            num_hists += 1\n",
    "\n",
    "print(f\"filled {num_hists} histograms, total size: {out[\"hist\"].view(True).nbytes / 1_000 / 1_000:.2f} MB\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a29cc-eec3-4b21-8a84-d6b2ea3f3732",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"walltime: {t1 - t0:.2f} sec ({(t1 - t0) / 60:.2f} min)\")\n",
    "print(f\"average worker count: {nworker_avg:.1f}\")\n",
    "print(f\"number of events processed: {report[\"entries\"]:,}\\n\")\n",
    "\n",
    "print(f\"data read: {report[\"bytesread\"] / 1000**3:.2f} GB in {report[\"chunks\"]} chunks (average {report[\"bytesread\"] / 1000**3 / report[\"chunks\"]:.2f} GB per chunk)\")\n",
    "print(f\"average total data rate: {report[\"bytesread\"] / 1000**3 * 8 / (t1 - t0):.2f} Gbps\")\n",
    "print(f\"fraction of input files read: {report[\"bytesread\"] / 1000**3 / input_size_GB:.1%}\")\n",
    "print(f\"number of branches read: {len(report[\"columns\"])}\\n\")\n",
    "\n",
    "print(f\"worker-average event rate using \\'processtime\\': {report[\"entries\"] / 1000 / report[\"processtime\"]:.2f} kHz\")\n",
    "print(f\"worker-average data rate using \\'processtime\\': {report[\"bytesread\"] / 1000**3 * 8 / report[\"processtime\"]:.2f} Gbps\\n\")\n",
    "\n",
    "print(f\"average event rate using walltime and time-averaged worker count: {report[\"entries\"] / 1000 / (t1 - t0) / nworker_avg:.2f} kHz\")\n",
    "print(f\"average data rate using walltime and time-averaged worker count: {report[\"bytesread\"] / 1000**3 * 8 / (t1 - t0) / nworker_avg:.2f} Gbps\\n\")\n",
    "\n",
    "print(f\"fraction of time spent in processing: {report[\"processtime\"] / ((t1 - t0) * nworker_avg):.1%}\")\n",
    "print(f\"average process task length: {report[\"processtime\"] / report[\"chunks\"]:.1f} sec\")\n",
    "\n",
    "timestamps, datarates = utils.calculate_instantaneous_rates(t0, t1, report, num_samples=50)\n",
    "_ = utils.plot_worker_count(worker_count_dict, timestamps, datarates)\n",
    "\n",
    "# visualize task stream\n",
    "ts = client.get_task_stream(start=f\"{math.ceil(time.time()-t0)}s\")\n",
    "_ = utils.plot_taskstream(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982cce52-7f5c-4126-a5cc-6a4dfee70732",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_stack = []\n",
    "labels = []\n",
    "for cat in sorted(out[\"hist\"].axes[1]):\n",
    "    if cat in [\"data\", \"ttbar_H7\", \"ttbar_hdamp\", \"ttbar_pthard\", \"Wt_DS\", \"Wt_H7\", \"Wt_pthard\", \"Hplus_cb\"]:\n",
    "        continue  # data drawn separately, skip MC modeling variations and signal\n",
    "\n",
    "    mc_stack.append(out[\"hist\"][:, cat, \"NOSYS\"])\n",
    "    labels.append(cat)\n",
    "\n",
    "try:\n",
    "    data_hist = out[\"hist\"][:, \"data\", \"NOSYS\"]\n",
    "except KeyError:\n",
    "    print(\"falling back to plotting first entry of categorical axes as \\\"data\\\"\")\n",
    "    data_hist = out[\"hist\"][:, 0, 0]\n",
    "\n",
    "fig, ax1, ax2 = mplhep.comp.data_model(\n",
    "    data_hist=data_hist,\n",
    "    stacked_components=mc_stack,\n",
    "    stacked_labels=labels,\n",
    "    # https://scikit-hep.org/mplhep/gallery/model_with_stacked_and_unstacked_histograms_components/\n",
    "    # unstacked_components=[],\n",
    "    # unstacked_labels=[],\n",
    "    xlabel=out[\"hist\"].axes[0].label,\n",
    "    ylabel=\"Entries\",\n",
    ")\n",
    "\n",
    "mplhep.atlas.label(\"Internal\", ax=ax1, data=True, lumi=f\"{utils.integrated_luminosity(\"\", total=True) / 1000:.0f}\", com=\"13/ \\\\ 13.6 \\\\ TeV\")\n",
    "mplhep.mpl_magic(ax=ax1)\n",
    "ax2.set_ylim([0.5, 1.5])\n",
    "\n",
    "# compare to e.g. https://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PAPERS/HDBS-2020-11/fig_02a.png\n",
    "fig.savefig(f\"{utils.get_output_path()}/mjj.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e3efe0-f724-4206-b233-202a51729014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk\n",
    "import uhi.io.json\n",
    "\n",
    "with gzip.open(f\"{utils.get_output_path()}/hist.json.gz\", \"w\") as f:\n",
    "    f.write(json.dumps(out[\"hist\"], default=uhi.io.json.default).encode(\"utf-8\"))\n",
    "\n",
    "with gzip.open(f\"{utils.get_output_path()}/hist.json.gz\") as f:\n",
    "    h = hist.Hist(json.loads(f.read(), object_hook=uhi.io.json.object_hook))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257ffb0c-33ee-4670-97e0-c8e7fbbdcdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evts_success = 0\n",
    "evts_all = 0\n",
    "num_failed = 0\n",
    "for (fname, start, stop), (t0, t1, bytesread) in report[\"chunk_info\"].items():\n",
    "    if bytesread == 0:\n",
    "        # print(fname, start, stop, t0, t1, bytesread)\n",
    "        num_failed += 1\n",
    "    else:\n",
    "        evts_success += stop-start\n",
    "    evts_all += stop-start\n",
    "print(f\"{num_failed} chunks failed\")\n",
    "print(f\"{evts_success} events successful, {evts_success/evts_all:.2%} completion rate\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
